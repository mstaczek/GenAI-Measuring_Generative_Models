{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - ConvNextV2\n",
    "\n",
    "https://huggingface.co/facebook/convnextv2-tiny-1k-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:\\win_programs\\python_venvs\\gnn-homeworks\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model=\"facebook/convnextv2-tiny-1k-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "    \n",
    "def classify_images(folder_name, output_suffix, drive_path_root):\n",
    "\n",
    "    path_to_images = drive_path_root + '/' + folder_name\n",
    "\n",
    "    image_paths = [path_to_images +'/'+p for p in os.listdir(path_to_images) if p.endswith(\".png\")]\n",
    "    print(f'Found {len(image_paths)} images in {path_to_images}')\n",
    "\n",
    "    model_predictions_top_5 = []\n",
    "    model_predictions_top_1 = []\n",
    "\n",
    "    for image_path in tqdm(image_paths):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        prediction = classifier(image)\n",
    "        model_predictions_top_5.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"predictions\": prediction\n",
    "        })\n",
    "        model_predictions_top_1.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"prediction\": prediction[0]['label'],\n",
    "            \"score\": round(prediction[0]['score'], 2)\n",
    "        })\n",
    "\n",
    "    output_top_1_name = f\"classifier_predictions_top_1_{output_suffix}.csv\"\n",
    "    output_top_5_name = f\"classifier_predictions_top_5_{output_suffix}.csv\"\n",
    "\n",
    "    # save model_predictions_top_1 as a csv\n",
    "    df = pd.DataFrame(model_predictions_top_1)\n",
    "    df.to_csv(output_top_1_name, index=True)\n",
    "\n",
    "    # save model_predictions_top_5 as a csv\n",
    "    # model_predictions_top_5 has a nested list of dictionaries, so we need to flatten it\n",
    "    model_predictions_all_flat = []\n",
    "    for image in model_predictions_top_5:\n",
    "        for prediction_position, prediction in enumerate(image['predictions']):\n",
    "            model_predictions_all_flat.append({\n",
    "                \"image_path\": image['image_path'],\n",
    "                \"prediction_position\": prediction_position,\n",
    "                \"label\": prediction['label'],\n",
    "                \"score\": round(prediction['score'], 2)\n",
    "            })\n",
    "\n",
    "    # save model_predictions_all_flat as a csv\n",
    "    df = pd.DataFrame(model_predictions_all_flat)\n",
    "    df.to_csv(output_top_5_name, index=True)\n",
    "\n",
    "    # copy to google drive\n",
    "    shutil.copyfile(output_top_1_name, drive_path_root + '/' + output_top_1_name)\n",
    "    print(\"Finished, saved to\", drive_path_root + '/' + output_top_1_name)\n",
    "\n",
    "    shutil.copyfile(output_top_5_name, drive_path_root + '/' + output_top_5_name)\n",
    "    print(\"Finished, saved to\", drive_path_root + '/' + output_top_5_name)\n",
    "\n",
    "    # clean up\n",
    "    os.remove(output_top_1_name)\n",
    "    os.remove(output_top_5_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images in datasets_generated_ready_models/stylegan2/generated_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:45<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished, saved to datasets_generated_ready_models/stylegan2/classifier_predictions_top_1_cars.csv\n",
      "Finished, saved to datasets_generated_ready_models/stylegan2/classifier_predictions_top_5_cars.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "root_path = \"datasets_generated_ready_models/stylegan2\"\n",
    "folder_name = \"generated_images\"\n",
    "output_suffix = 'cars'\n",
    "\n",
    "classify_images(folder_name, output_suffix, drive_path_root=root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection\n",
    "\n",
    "Source: https://docs.ultralytics.com/models/yolov8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralyticsplus import YOLO\n",
    "\n",
    "# load model\n",
    "model = YOLO('ultralyticsplus/yolov8m')\n",
    "\n",
    "# known classes from https://huggingface.co/ultralyticsplus/yolov8s\n",
    "known_classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# set model parameters\n",
    "model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "model.overrides['max_det'] = 100  # maximum number of detections per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "\n",
    "def detect_objects_on_images(folder_name, output_suffix, drive_path_root, known_classes=known_classes):\n",
    "\n",
    "    path_to_images = drive_path_root + '/' + folder_name\n",
    "\n",
    "    image_paths = [path_to_images +'/'+p for p in os.listdir(path_to_images) if p.endswith(\".png\")]\n",
    "    print(f'Found {len(image_paths)} images in {path_to_images}')\n",
    "\n",
    "    detected_objects = []\n",
    "    results_images_with_boxes = []\n",
    "\n",
    "    for image_path in tqdm(image_paths):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        results = model.predict(image, verbose=False)\n",
    "\n",
    "        # add detected objects with confidence to list\n",
    "        for i in range(len(results)):\n",
    "            for j in range(len(results[i].boxes)):\n",
    "                predicted_class = known_classes[results[i].boxes[j].cls.int().item()]\n",
    "                confidence = round(results[i].boxes[j].conf.item(), 2)\n",
    "\n",
    "                detected_objects.append({\n",
    "                    \"image_path\": image_path,\n",
    "                    \"predicted_class\": predicted_class,\n",
    "                    \"confidence\": confidence\n",
    "                })\n",
    "\n",
    "        # add image with boxes to list\n",
    "        results_images_with_boxes.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"results\": results[0]\n",
    "        })\n",
    "\n",
    "    output_detected_objects_name = f\"detected_objects_{output_suffix}.csv\"\n",
    "    output_images_with_boxes_name = f\"images_with_boxes_{output_suffix}\"\n",
    "\n",
    "    # save detected_objects as a csv\n",
    "    df = pd.DataFrame(detected_objects)\n",
    "    df.to_csv(output_detected_objects_name, index=True)\n",
    "\n",
    "    # save images_with_boxes as a zip\n",
    "    os.makedirs(output_images_with_boxes_name, exist_ok=True)\n",
    "    for image in results_images_with_boxes:\n",
    "        image['results'].save(output_images_with_boxes_name + '/' + image['image_path'].split('/')[-1])\n",
    "\n",
    "    # zip the folder\n",
    "    shutil.make_archive(output_images_with_boxes_name, 'zip', output_images_with_boxes_name)\n",
    "\n",
    "    # # copy to google drive\n",
    "    shutil.copyfile(output_detected_objects_name, drive_path_root + '/' + output_detected_objects_name)\n",
    "    print(\"Finished, saved to\", drive_path_root + '/' + output_detected_objects_name)\n",
    "\n",
    "    shutil.copyfile(output_images_with_boxes_name + '.zip', drive_path_root + '/' + output_images_with_boxes_name + '.zip')\n",
    "    print(\"Finished, saved to\", drive_path_root + '/' + output_images_with_boxes_name + '.zip')\n",
    "    \n",
    "    # # clean up\n",
    "    shutil.rmtree(output_images_with_boxes_name)\n",
    "    os.remove(output_detected_objects_name)\n",
    "    os.remove(output_images_with_boxes_name + '.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images in datasets_generated_ready_models/stylegan2/generated_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:40<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished, saved to datasets_generated_ready_models/stylegan2/detected_objects_cars.csv\n",
      "Finished, saved to datasets_generated_ready_models/stylegan2/images_with_boxes_cars.zip\n"
     ]
    }
   ],
   "source": [
    "root_path = \"datasets_generated_ready_models/stylegan2\"\n",
    "folder_name = \"generated_images\"\n",
    "output_suffix = 'cars'\n",
    "\n",
    "detect_objects_on_images(folder_name, output_suffix, drive_path_root=root_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-homeworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
