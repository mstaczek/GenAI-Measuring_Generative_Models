{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a pre-trained sentence-transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_average_cosine_similarity(prompts, captions, embedding_model=model):\n",
    "    # Compute sentence embeddings\n",
    "    prompt_embeddings = embedding_model.encode(prompts)\n",
    "    caption_embeddings = embedding_model.encode(captions)\n",
    "\n",
    "    # for every sentence embedding in list a and b, compute the cosine similarity. Then, take the average of all the cosine similarities\n",
    "    similarities_list = []\n",
    "    for i in tqdm(range(len(prompt_embeddings))):\n",
    "        similarities_list.append(cosine_similarity([prompt_embeddings[i]], [caption_embeddings[i]]))\n",
    "\n",
    "    average_cosine_similarity = sum(similarities_list) / len(similarities_list)\n",
    "    return round(average_cosine_similarity.item(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1673.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example usage\n",
    "get_average_cosine_similarity([\"The quick brown fox jumps over the lazy dog.\", \"I love coding in Python\"],\n",
    "                               [\"A lazy dog is jumped over by a quick brown fox.\", \"Python is my favorite programming language.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mean cosine similarity between prompts and captions - CARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "car_prompts_archive = 'datasets_generated_ready_models\\SD_XL\\cars_zipped.zip'\n",
    "car_prompts_name = 'cars_prompts.txt'\n",
    "car_captions_sdxl_path = 'datasets_generated_ready_models\\SD_XL\\image_captions_cars_zipped.txt'\n",
    "car_captions_dalle3_path = 'datasets_generated_ready_models\\DALLE3\\image_captions_dalle_cars_zipped.txt'\n",
    "\n",
    "with zipfile.ZipFile(car_prompts_archive) as z:\n",
    "    with z.open(car_prompts_name) as f:\n",
    "        car_prompts = f.read().decode('utf-8').splitlines()\n",
    "\n",
    "with open(car_captions_sdxl_path, 'r', encoding='utf-8') as f:\n",
    "    car_captions_sdxl = f.read().splitlines()\n",
    "\n",
    "with open(car_captions_dalle3_path, 'r', encoding='utf-8') as f:\n",
    "    car_captions_dalle3 = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 2275.38it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1692.89it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 2287.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between prompts and SD_XL captions: 0.278\n",
      "Mean similarity between prompts and DALL-E 3 captions: 0.26\n",
      "Mean similarity between SD_XL and DALL-E 3 captions: 0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_similarity_sdxl = get_average_cosine_similarity(car_prompts, car_captions_sdxl)\n",
    "mean_similarity_dalle3 = get_average_cosine_similarity(car_prompts, car_captions_dalle3)\n",
    "\n",
    "mean_similarity_sdxl_dalle3 = get_average_cosine_similarity(car_captions_sdxl, car_captions_dalle3)\n",
    "\n",
    "print(f\"Mean similarity between prompts and SD_XL captions: {mean_similarity_sdxl}\")\n",
    "print(f\"Mean similarity between prompts and DALL-E 3 captions: {mean_similarity_dalle3}\")\n",
    "\n",
    "print(f\"Mean similarity between SD_XL and DALL-E 3 captions: {mean_similarity_sdxl_dalle3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mean cosine similarity between prompts and captions - WILDLIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "wildlife_prompts_archive = 'datasets_generated_ready_models\\SD_XL\\wildlife_zipped.zip'\n",
    "wildlife_prompts_name = 'wildlife_prompts.txt'\n",
    "wildlife_captions_sdxl_path = 'datasets_generated_ready_models\\SD_XL\\image_captions_wildlife_zipped.txt'\n",
    "wildlife_captions_dalle3_path = 'datasets_generated_ready_models\\DALLE3\\image_captions_dalle_wildlife_zipped.txt'\n",
    "\n",
    "with zipfile.ZipFile(wildlife_prompts_archive) as z:\n",
    "    with z.open(wildlife_prompts_name) as f:\n",
    "        wildlife_prompts = f.read().decode('utf-8').splitlines()\n",
    "\n",
    "with open(wildlife_captions_sdxl_path, 'r', encoding='utf-8') as f:\n",
    "    wildlife_captions_sdxl = f.read().splitlines()\n",
    "\n",
    "with open(wildlife_captions_dalle3_path, 'r', encoding='utf-8') as f:\n",
    "    wildlife_captions_dalle3 = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 2683.63it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 2246.38it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 2225.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between prompts and SD_XL captions: 0.259\n",
      "Mean similarity between prompts and DALL-E 3 captions: 0.248\n",
      "Mean similarity between SD_XL and DALL-E 3 captions: 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_similarity_sdxl = get_average_cosine_similarity(wildlife_prompts, wildlife_captions_sdxl)\n",
    "mean_similarity_dalle3 = get_average_cosine_similarity(wildlife_prompts, wildlife_captions_dalle3)\n",
    "\n",
    "mean_similarity_sdxl_dalle3 = get_average_cosine_similarity(wildlife_captions_sdxl, wildlife_captions_dalle3)\n",
    "\n",
    "print(f\"Mean similarity between prompts and SD_XL captions: {mean_similarity_sdxl}\")\n",
    "print(f\"Mean similarity between prompts and DALL-E 3 captions: {mean_similarity_dalle3}\")\n",
    "\n",
    "print(f\"Mean similarity between SD_XL and DALL-E 3 captions: {mean_similarity_sdxl_dalle3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mean cosine similarity between prompts and captions - BRECAHAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "brecahad_prompts_archive = 'datasets_generated_ready_models\\SD_XL\\\\brecahad_zipped.zip'\n",
    "brecahad_prompts_name = 'brecahad_prompts.txt'\n",
    "brecahad_captions_sdxl_path = 'datasets_generated_ready_models\\SD_XL\\image_captions_brecahad_zipped.txt'\n",
    "brecahad_captions_dalle3_path = 'datasets_generated_ready_models\\DALLE3\\image_captions_dalle_brecahad_zipped.txt'\n",
    "\n",
    "with zipfile.ZipFile(brecahad_prompts_archive) as z:\n",
    "    with z.open(brecahad_prompts_name) as f:\n",
    "        brecahad_prompts = f.read().decode('utf-8').splitlines()\n",
    "        # remove line 4, not present in dalle3 images\n",
    "        brecahad_prompts = brecahad_prompts[:3] + brecahad_prompts[4:]\n",
    "\n",
    "with open(brecahad_captions_sdxl_path, 'r', encoding='utf-8') as f:\n",
    "    brecahad_captions_sdxl = f.read().splitlines()\n",
    "    # remove line 4, not present in dalle3 images\n",
    "    brecahad_captions_sdxl = brecahad_captions_sdxl[:3] + brecahad_captions_sdxl[4:]\n",
    "\n",
    "with open(brecahad_captions_dalle3_path, 'r', encoding='utf-8') as f:\n",
    "    brecahad_captions_dalle3 = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 2249.89it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 563.62it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 984.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between prompts and SD_XL captions: 0.214\n",
      "Mean similarity between prompts and DALL-E 3 captions: 0.167\n",
      "Mean similarity between SD_XL and DALL-E 3 captions: 0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_similarity_sdxl = get_average_cosine_similarity(brecahad_prompts, brecahad_captions_sdxl)\n",
    "mean_similarity_dalle3 = get_average_cosine_similarity(brecahad_prompts, brecahad_captions_dalle3)\n",
    "\n",
    "mean_similarity_sdxl_dalle3 = get_average_cosine_similarity(brecahad_captions_sdxl, brecahad_captions_dalle3)\n",
    "\n",
    "print(f\"Mean similarity between prompts and SD_XL captions: {mean_similarity_sdxl}\")\n",
    "print(f\"Mean similarity between prompts and DALL-E 3 captions: {mean_similarity_dalle3}\")\n",
    "\n",
    "print(f\"Mean similarity between SD_XL and DALL-E 3 captions: {mean_similarity_sdxl_dalle3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-homeworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
